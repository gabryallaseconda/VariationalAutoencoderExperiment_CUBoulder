{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoders\n",
    "\n",
    "This project is an experimentation to implement a variational autoencoder.\n",
    "\n",
    "The focus here is not on implementation but on the mathematics of these tools.\n",
    "\n",
    "We focus on images. Our model will be tested on two well-known dataset: the FashionMNIST and the MNIST datasets. Our goal is to new generate images form the training data.\n",
    "\n",
    "Here the structure of a variational autoencoder (credits to Wikipedia):\n",
    "\n",
    "![Autoencoder Schema Wikipedia](Reparameterized_Variational_Autoencoder.png)\n",
    "\n",
    "Notes on **hyperparameter tuning**:\n",
    "- H_DIM at least 150, more than 300 doesn't seems to have effects\n",
    "- Z_DIM 20 is fine, if lower than 15 the generation will produce far worse results\n",
    "- NUM_EPOCHS at least 10, 20 is good\n",
    "- LR_RATE 3e-4 is fine, you can double it if you increase the number of epochs\n",
    "- ALPHA regulates the mixture of losses, if alpha=1 all the generated images will be the same\n",
    "\n",
    "I learned some ideas from https://github.com/karpathy/minGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.backends.mps.is_available():\n",
    "        DEVICE = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "        DEVICE = torch.device('cuda')\n",
    "else:\n",
    "        DEVICE = torch.device('cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input img -> hidden dim -> mean, std -> parametrization trick -> deocder -> output img\n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Here is the pipeline:\n",
    "    Get the image (relu, linear)\n",
    "    Dense layer - encoder(linear)\n",
    "    Split in mu and sigma (two linears)\n",
    "    Add noise, aka parametrization trick, get the code\n",
    "    Dense layer - decoder (linear)\n",
    "    Output the image (linear, sigmoid)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, h_dim = 200, z_dim =20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.img_2hid = nn.Linear(input_dim, h_dim)\n",
    "        self.hid_2mu = nn.Linear(h_dim, z_dim)\n",
    "        self.hid_2sigma = nn.Linear(h_dim, z_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.z_2hid = nn.Linear(z_dim, h_dim)\n",
    "        self.hid_2img = nn.Linear(h_dim, input_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.img_2hid(x))\n",
    "        mu, sigma = self.hid_2mu(h), self.hid_2sigma(h)\n",
    "        \n",
    "        return mu, sigma\n",
    "        \n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = self.relu(self.z_2hid(z))\n",
    "        \n",
    "        return torch.sigmoid(self.hid_2img(h)) # we must be sure that values are from 0 to 1, because we normalized the image.\n",
    "        \n",
    "    def forward(self, x):\n",
    "         \n",
    "        mu, sigma = self.encode(x)\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        \n",
    "        z_reparametrized = mu + sigma*epsilon\n",
    "        x_reconstructed = self.decode(z_reparametrized)\n",
    "        \n",
    "        return x_reconstructed, mu, sigma\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "DEVICE = torch.device('mps')\n",
    "\n",
    "# FashionMNIST and MNIST have 28x28 dimension\n",
    "INPUT_DIM = 784\n",
    "\n",
    "H_DIM = 300        # more power in terms of understanding the features in the image\n",
    "Z_DIM = 20         # more compression\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "LR_RATE = 3e-4 \n",
    "\n",
    "ALPHA = .5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, train_loader, optimizer, loss_fn, alpha):\n",
    "    for epoch in range(num_epochs):\n",
    "        loop = tqdm(enumerate(train_loader))\n",
    "        for i, (x, _) in loop:\n",
    "            \n",
    "            \n",
    "            x=x.to(DEVICE).view(x.shape[0], INPUT_DIM)\n",
    "            x_reconstructed, mu, sigma = model(x)\n",
    "            \n",
    "            # compute loss\n",
    "            reconstruction_loss =loss_fn(x_reconstructed, x)   # help in reconstruciton\n",
    "            kl_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2)) # kl divergence  # shirnk to gaussian\n",
    "            loss = alpha*reconstruction_loss + (1-alpha)*kl_div\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm(model.parameters(p)\n",
    "            optimizer.step()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kullback-Leibler Divergence\n",
    "$$ \\text{KL}\\left(q(z | x) \\| p(z)\\right) = -\\frac{1}{2} \\sum_{i=1}^{N} \\left(1 + \\log(\\sigma_i^2) - \\mu_i^2 - \\sigma_i^2\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, labels, folder, dataset, n_examples=1):\n",
    "    \n",
    "    len_labels = len(labels)\n",
    "    \n",
    "    for label in labels:\n",
    "    \n",
    "        images = []\n",
    "        idx = 0\n",
    "        for x, y in dataset:\n",
    "            if y == idx:\n",
    "                images.append(x)\n",
    "                idx += 1\n",
    "            if idx == len_labels:\n",
    "                break\n",
    "        \n",
    "        encodings_digit = []\n",
    "        \n",
    "        for d in range(len_labels):\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                mu, sigma = model.encode(images[d].view(1, 784).to(DEVICE))\n",
    "            \n",
    "            encodings_digit.append((mu, sigma))\n",
    "\n",
    "        mu, sigma = encodings_digit[label]\n",
    "        \n",
    "        for example in range(n_examples):\n",
    "            epsilon = torch.randn_like(sigma)\n",
    "            z = mu + sigma * epsilon\n",
    "            out = model.decode(z)\n",
    "            out = out.view(-1, 1, 28, 28)\n",
    "            save_image(out, folder + f\"/label_{label}_{example}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from standard datasets of pytorch\n",
    "dataset = datasets.FashionMNIST(root=\"dataset/\", train = True, transform = transforms.ToTensor(), download = True)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size = BATCH_SIZE, shuffle=True) #not using workers!\n",
    "\n",
    "# instantiate the model we build\n",
    "model = VariationalAutoEncoder(INPUT_DIM, H_DIM, Z_DIM).to(DEVICE)\n",
    "\n",
    "# set the optimizer ( one here can add also the scheduler)\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR_RATE)\n",
    "\n",
    "# set the loss function\n",
    "loss_fn = nn.BCELoss(reduction='sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:23, 80.23it/s, loss=4.64e+3]\n",
      "1875it [00:22, 83.61it/s, loss=4.12e+3]\n",
      "1875it [00:22, 83.10it/s, loss=4.44e+3]\n",
      "1875it [00:22, 84.04it/s, loss=4.11e+3]\n",
      "1875it [00:22, 84.39it/s, loss=4.04e+3]\n",
      "1875it [00:22, 82.82it/s, loss=4.18e+3]\n",
      "1875it [00:22, 83.61it/s, loss=4.15e+3]\n",
      "1875it [00:22, 82.48it/s, loss=4.17e+3]\n",
      "1875it [00:22, 82.81it/s, loss=4.51e+3]\n",
      "1875it [00:23, 79.00it/s, loss=4.4e+3] \n",
      "1875it [00:22, 82.12it/s, loss=4.24e+3]\n",
      "1875it [00:21, 87.08it/s, loss=4.11e+3]\n",
      "1875it [00:22, 84.15it/s, loss=4.56e+3]\n",
      "1875it [00:22, 83.45it/s, loss=4.38e+3]\n",
      "1875it [00:23, 80.05it/s, loss=4.67e+3]\n",
      "1875it [00:23, 79.20it/s, loss=4.84e+3]\n",
      "1875it [00:22, 83.05it/s, loss=4.04e+3]\n",
      "1875it [00:21, 85.63it/s, loss=4.48e+3]\n",
      "1875it [00:22, 84.80it/s, loss=4.28e+3]\n",
      "1875it [00:21, 86.05it/s, loss=4.41e+3]\n"
     ]
    }
   ],
   "source": [
    "model = train(model=model, num_epochs=NUM_EPOCHS, train_loader=train_loader, optimizer=optimizer, loss_fn=loss_fn, alpha=ALPHA)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all possible labels from dataset\n",
    "\n",
    "labels =  []\n",
    "for _, y in dataset:\n",
    "    labels.append(y)\n",
    "    \n",
    "labels = list(set(labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new images\n",
    "\n",
    "inference(model=model, labels=labels, dataset=dataset, folder= \"generated/fashion\", n_examples=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root=\"dataset/\", train = True, transform = transforms.ToTensor(), download = True)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size = BATCH_SIZE, shuffle=True) #not using workers!\n",
    "\n",
    "model = VariationalAutoEncoder(INPUT_DIM, H_DIM, Z_DIM).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = LR_RATE)\n",
    "\n",
    "loss_fn = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:22, 85.13it/s, loss=2.39e+3]\n",
      "1875it [00:21, 86.08it/s, loss=2.23e+3]\n",
      "1875it [00:22, 84.43it/s, loss=2.08e+3]\n",
      "1875it [00:21, 86.39it/s, loss=2.2e+3] \n",
      "1875it [00:22, 84.61it/s, loss=1.99e+3]\n",
      "1875it [00:22, 85.09it/s, loss=2.11e+3]\n",
      "1875it [00:21, 85.56it/s, loss=1.92e+3]\n",
      "1875it [00:22, 84.46it/s, loss=2.04e+3]\n",
      "1875it [00:21, 86.35it/s, loss=2.21e+3]\n",
      "1875it [00:22, 84.19it/s, loss=2.1e+3] \n",
      "1875it [00:23, 78.81it/s, loss=2.04e+3]\n",
      "1875it [00:22, 81.99it/s, loss=2.06e+3]\n",
      "1875it [00:22, 84.14it/s, loss=2.05e+3]\n",
      "1875it [00:22, 81.81it/s, loss=2.16e+3]\n",
      "1875it [00:22, 83.71it/s, loss=2.02e+3]\n",
      "1875it [00:21, 85.46it/s, loss=1.92e+3]\n",
      "257it [00:03, 84.49it/s, loss=1.91e+3]"
     ]
    }
   ],
   "source": [
    "model = train(model=model, num_epochs=NUM_EPOCHS, train_loader=train_loader, optimizer=optimizer, loss_fn=loss_fn, alpha=ALPHA)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Get all possible labels from dataset\n",
    "\n",
    "labels =  []\n",
    "for _, y in dataset:\n",
    "    labels.append(y)\n",
    "    \n",
    "labels = list(set(labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new images\n",
    "\n",
    "inference(model=model, labels=labels, dataset=dataset, folder= \"generated/mnist\", n_examples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-networks-_F4AaA2c-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
